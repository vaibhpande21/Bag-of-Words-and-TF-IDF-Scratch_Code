# ğŸ§  Bag of Words (BoW) & TF-IDF â€” Scratch Implementation

This project demonstrates the **from-scratch implementation** of two fundamental text vectorization techniques â€” **Bag of Words (BoW)** and **TF-IDF (Term Frequencyâ€“Inverse Document Frequency)** â€” without relying on libraries like `scikit-learn`.  
It aims to build a strong conceptual understanding of how raw text is converted into numerical vectors for use in machine learning models.

---

## ğŸš€ Features

- Created a **custom vocabulary** from a corpus.  
- Implemented **Count-Based BoW** and **Binary BoW** representations.  
- Calculated **Term Frequency (TF)** and **Inverse Document Frequency (IDF)** manually.  
- Combined them to produce **TF-IDF vectors** from scratch.  
- Visualized BoW and TF-IDF as matrices using `pandas`.

---

## âš™ï¸ How It Works

1. **Preprocessing** â€” Tokenize the corpus and build a vocabulary of unique words.  
2. **BoW Construction** â€” Count how many times each vocabulary word appears in each sentence/document.  
3. **TF Calculation** â€” Normalize word counts by sentence length.  
4. **IDF Calculation** â€” Compute how unique each word is across the corpus.  
5. **TF-IDF Representation** â€” Multiply TF and IDF to get the final vector.

---

## ğŸ§  Concepts

| Technique        | Description                                                   |
|------------------|---------------------------------------------------------------|
| **Bag of Words** | Converts text into vectors based on word counts or presence.  |
| **TF-IDF**       | Scales word counts by how important/rare the word is overall. |

---

## ğŸ§® Example Output

### **Corpus:**

```
["I love data science", "Data science is fun"]
```

### **BoW Representation:**

| i | love | data | science | is | fun |
|---|------|------|----------|----|-----|
| 1 | 1    | 1    | 1        | 0  | 0   |
| 0 | 0    | 1    | 1        | 1  | 1   |

### **TF-IDF Representation:**

| i   | love | data | science | is   | fun  |
|-----|------|------|----------|------|------|
| 0.70 | 0.70 | 0.35 | 0.35 | 0    | 0    |
| 0    | 0    | 0.35 | 0.35 | 0.70 | 0.70 |

---

## ğŸ§° Tech Stack

- **Python 3.9+**  
- `nltk` â€” for tokenization  
- `pandas`, `numpy` â€” for tabular and numerical operations  

---

## ğŸ¯ Learning Outcome

By building BoW and TF-IDF manually, this project reinforces:

- Core NLP preprocessing steps  
- Understanding of document vectorization  
- How libraries like scikit-learnâ€™s `CountVectorizer` & `TfidfVectorizer` work internally  

---

## ğŸ“„ Author

**Vaibhav Pandey**  
_Data Science Enthusiast | NLP Learner | Building from first principles_


